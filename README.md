# **Physics-Informed Neural‐Network Tracking for Ultrasound Localization Microscopy: A Feasibility Study on Rat-Brain Microvasculature**

###### DATE 2025.05.12

### **AUTHOR: Zhou Quan Eric Gao, University of California San Diego**

#### **Abstract:**

Ultrasound Localization Microscopy (ULM) overcomes the diffraction limit of conventional ultrasound by localizing and tracking microbubble contrast agents to visualize microvascular structures and flows with $\approx $ 10**µm** resolution. Recent advances in data-driven algorithms have improved ULM speed and robustness, but they do not explicitly enforce the physical laws governing blood flow. In this work, we propose a methodological innovation that integrates Physics-Informed Neural Networks (PINNs) with the simplified Navier–Stokes equations into ULM’s microbubble tracking algorithms. By embedding fluid dynamics principles into the neural network’s loss function, the proposed ULM-PINN framework ensures physically plausible motion estimations and produces continuous velocity fields of the microcirculation. We utilize publicly available in vivo rat brain datasets, ULM preprocessing scripts, and localization steps made public by Heiles et al (2022) [1]. Results show that PINN-based tracking yields coherent microbubble trajectories in in vivo flow scenarios and establishes the feasibility and theoretical benefits of PINN-guided tracking, providing final microbubble tracks consistent with physiological expectations.

#### **RELATED DATASET:**

In Vivo Rat Brain Dataset available here at: [Zenodo: `10.5281/zenodo.4343435`](https://doi.org/10.5281/zenodo.4343435) publically made available by Heiles, Chavignon, Hingot, Lopez, Teston and Couture.
[*Performance benchmarking of microbubble-localization algorithms for ultrasound localization microscopy*, Nature Biomedical Engineering, 2022, (doi.org/10.1038/s41551-021-00824-8](http://doi.org/10.1038/s41551-021-00824-8)

### What’s included

- This pipeline starts **after** the completion of the microbubble localization step and can end with:
  - a **plain (unmodified) brain map** from exported tracks (`Scripts/BrainMap Generation/visualize_mat_tracks.py`), or
  - **complete maps** (intensity + axial flow velocity + flow direction) (`Scripts/BrainMap Generation/FinalImage_MAT.m`).
- **Input**: a MATLAB `.mat` file containing `Coord_all` with columns `[Intensity, X, Z, ImageIndex]`
- **Pipeline**:
  - load + normalize detections
  - initial Hungarian tracking + per-track velocity estimation
  - PINN training (data loss + physics loss)
  - LAPJV + PINN-guided re-tracking
  - post-processing + export to MATLAB-compatible track `.mat`
- **Output**: a `runs/run_*/` folder with logs, loss curves, and exported tracks, plus optional downstream brain-map visualizations.

### Setup

- **Python**: 3.10+ recommended

Install dependencies:

```bash
python -m pip install -r requirements.txt
```

Notes:

- `torch` install depends on your platform and GPU setup; if you want CUDA support, install the appropriate PyTorch build from the official instructions.
- `scikit-learn` is optional (only used by some density-sampling modes).

### Full run (example)

Optional (recommended if using vessel-aware collocation sampling or wall/outside-vessel losses):

Generate a vessel mask from a localization CSV (expects `X` and `Z` columns by default):

```bash
python Scripts/vessel_mask_generation.py \
  --csv-path path/to/localizations.csv \
  --output-mask vessel_mask.npz \
  --output-viz vessel_mask.png
```

Then pass it to the main pipeline via `--vessel_mask_path` (and optionally tune `--colloc_sampling_mode`, `--wall_loss_weight`, `--outside_vessel_loss_weight`).

```bash
python Scripts/main.py \
  --mat_file InVivoRatBrain_Coordinates.mat (localized microbubble mat file path) \
  --epochs 2000 \
  --n_colloc 5000 \
  --vessel_mask_path vessel_mask.npz
```

Optional downstream visualization / brain-map generation:

- Plain (unmodified) brain map from MATLAB track output:

```bash
python "Scripts/BrainMap Generation/visualize_mat_tracks.py" \
  --mat_file runs/run_YYYYMMDD_HHMMSS/*_PINN_tracks.mat
```

- Complete intensity + axial flow velocity + flow direction maps (MATLAB):
  - Open and run `Scripts/BrainMap Generation/FinalImage_MAT.m`
  - Point it at the exported track `.mat` (e.g., `runs/run_YYYYMMDD_HHMMSS/*_PINN_tracks.mat`)

### Outputs

Each run creates a folder like:

- `runs/run_YYYYMMDD_HHMMSS/`
  - `run.log`
  - `parameters.json`, `parameters.txt`
  - `loss_curve.png` (+ a few truncated versions)
  - `*_PINN_tracks.mat` (final MATLAB-compatible tracks)
  - (optional) brain-map figures generated by:
    - `Scripts/BrainMap Generation/visualize_mat_tracks.py` (plain brain map), and/or
    - `Scripts/BrainMap Generation/FinalImage_MAT.m` (intensity + axial velocity + flow direction maps)

### Repo layout

- `Scripts/main.py`: main end-to-end pipeline entrypoint
- `Scripts/pinn_model.py`: publishable PINN + training loop
- `Scripts/tracking.py`: tracking + LAPJV/PINN guided linking
- `Scripts/post_processing.py`: interpolation, unnormalization, `.mat` export
